{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 试试\n",
    "\n",
    "代码来自 `tutorial\\6.1_chinese_dataset_uer_t5.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.pipeline_base import PromptForGeneration\n",
    "from openprompt.prompts.generation_verbalizer import GenerationVerbalizer\n",
    "from tqdm import tqdm\n",
    "from openprompt.data_utils import PROCESSORS\n",
    "import torch\n",
    "from openprompt.data_utils.utils import InputExample\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from openprompt import PromptDataLoader\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "from openprompt.prompts import SoftTemplate\n",
    "from openprompt import PromptForClassification\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from openprompt.utils.crossfit_metrics import evaluate as crossfit_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    max_steps = 5000\n",
    "    lr = 1e-2\n",
    "    warmup_step_prompt = 500\n",
    "    eval_every_steps = 500\n",
    "\n",
    "args = Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'extra0 北 extra1 extra2 extra3 extra4 extra5 extra6 extra7 extra8 extra9 extra10 extra11 extra12 extra13 extra14 extra15 extra16 extra17 extra18 extra19 extra9'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, MT5ForConditionalGeneration, Text2TextGenerationPipeline, T5ForConditionalGeneration\n",
    "\n",
    "# 应该用 T5ForConditionalGeneration 的\n",
    "\n",
    "model_dir = \"uer/t5-v1_1-base-chinese-cluecorpussmall\"\n",
    "model_dir = r\"G:\\code\\pretrain_model_dir\\t5-base-chinese-cluecorpussmall\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "text2text_generator = Text2TextGenerationPipeline(model, tokenizer)\n",
    "generated_text = text2text_generator(\"中国的首都是extra0京\", max_length=50, do_sample=False)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.plms.seq2seq import T5TokenizerWrapper\n",
    "\n",
    "\n",
    "class T5BertTokenizerWrapper(T5TokenizerWrapper):\n",
    "    def mask_token(self, id):\n",
    "        return f\"extra{id}\"\n",
    "\n",
    "    def mask_token_ids(self, id):\n",
    "        return self.tokenizer.convert_tokens_to_ids(f\"extra{id}\")\n",
    "\n",
    "\n",
    "# 这里将终止符改成了 extra1, 只要输出一个选项就可以了\n",
    "tokenizer.eos_token = \"extra1\"\n",
    "tokenizer_wrapper = T5BertTokenizerWrapper(\n",
    "    max_seq_length=128, tokenizer=tokenizer, decoder_max_length=5, decode_from_pad=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"G:\\dataset\\text_classify\\诗歌分类\"\n",
    "def load_local_dataset(path=\"../CCPM/\", split=\"train\"):\n",
    "    import json\n",
    "\n",
    "    with open(f\"{path}/{split}.jsonl\", \"r\", encoding=\"utf-8\") as fin:\n",
    "        L = fin.readlines()\n",
    "    data = []\n",
    "    for json_str in L:\n",
    "        result = json.loads(json_str)\n",
    "        # from IPython import embed; embed()\n",
    "        for idx, choice in enumerate(result[\"choices\"]):\n",
    "            result[f\"choice{idx}\"] = choice\n",
    "        result.pop(\"choices\")\n",
    "        data.append(InputExample(meta=result, label=int(result[\"answer\"])))\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset = {}\n",
    "dataset[\"train\"] = load_local_dataset(path=data_dir, split=\"train\")\n",
    "dataset[\"val\"] = load_local_dataset(path=data_dir, split=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"guid\": null,\n",
       "  \"label\": 1,\n",
       "  \"meta\": {\n",
       "    \"answer\": 1,\n",
       "    \"choice0\": \"行人初上木兰舟\",\n",
       "    \"choice1\": \"骚人遥驻木兰舟\",\n",
       "    \"choice2\": \"有人独上木兰舟\",\n",
       "    \"choice3\": \"行人迢递木兰舟\",\n",
       "    \"translation\": \"诗人啊，你竟像在遥远的地方站立船头。\"\n",
       "  },\n",
       "  \"text_a\": \"\",\n",
       "  \"text_b\": \"\",\n",
       "  \"tgt_text\": \"二\"\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 21778it [00:19, 1128.57it/s]\n",
      "tokenizing: 2720it [00:02, 1183.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 一 ： 寥 寥 清 磬 闻 ； 二 ： 寥 寥 竟 不 闻 ； 三 ： 寥 寥 不 复 闻 ； 四 ： 寥 寥 不 可 闻 。 哪 一 句 表 达 了 下 面 的 意 思 : 后 来 几 乎 闻 所 未 闻 了 ？ 第 extra0 句 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "extra0 四 [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "\n",
    "mytemplate = ManualTemplate(\n",
    "    tokenizer=tokenizer,\n",
    "    text=\"\"\"一：{\"meta\":\"choice0\"}； 二： {\"meta\":\"choice1\"}； 三： {\"meta\":\"choice2\"}； 四：{\"meta\":\"choice3\"}。哪一句表达了下面的意思: {\"meta\":\"translation\", \"shortenable\":True, \"post_processing\": lambda x:x.strip('。')}？第{\"mask\"}句。 \"\"\",\n",
    ")\n",
    "myverbalizer = GenerationVerbalizer(tokenizer, label_words={0: \"一\", 1: \"二\", 2: \"三\", 3: \"四\"}, is_rule=False)\n",
    "train_dataloader = PromptDataLoader(\n",
    "    dataset=dataset[\"train\"],\n",
    "    template=mytemplate,\n",
    "    verbalizer=myverbalizer,  # be sure to add verbalizer\n",
    "    tokenizer_wrapper=tokenizer_wrapper,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    teacher_forcing=True,\n",
    "    predict_eos_token=True,\n",
    "    truncate_method=\"tail\",\n",
    ")\n",
    "validation_dataloader = PromptDataLoader(\n",
    "    dataset=dataset[\"val\"],\n",
    "    template=mytemplate,\n",
    "    verbalizer=myverbalizer,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_wrapper=tokenizer_wrapper,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    teacher_forcing=False,\n",
    "    predict_eos_token=False,  # predict_eos_token=True or False are both ok\n",
    "    truncate_method=\"tail\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 一 ： 明 日 知 何 处 ； 二 ： 近 日 何 多 念 ； 三 ： 明 日 何 其 多 ； 四 ： 明 日 复 何 之 。 哪 一 句 表 达 了 下 面 的 意 思 : 明 天 何 等 的 多 ？ 第 extra0 句 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "extra0 四 [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# visualize some encoded data\n",
    "print(tokenizer.decode(next(iter(train_dataloader))[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(next(iter(train_dataloader))[\"decoder_input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncate rate: 0.02559392603477835\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "prompt_model = PromptForGeneration(plm=model, template=mytemplate, freeze_plm=False, plm_eval_mode=False)\n",
    "if use_cuda:\n",
    "    prompt_model = prompt_model.cuda()\n",
    "\n",
    "print(\"truncate rate: {}\".format(train_dataloader.tokenizer_wrapper.truncate_rate), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_arguments = {\n",
    "    \"max_new_tokens\": 1,\n",
    "}\n",
    "\n",
    "def evaluate(prompt_model, dataloader):\n",
    "    \"\"\"\n",
    "    评估方法\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        _, output_sentence = prompt_model.generate(inputs, **generation_arguments, verbose=False)\n",
    "        predictions.extend(output_sentence)\n",
    "        ground_truths.extend(inputs[\"tgt_text\"])\n",
    "    assert len(predictions) == len(ground_truths), (len(predictions), len(ground_truths))\n",
    "    predictions = [prediction.strip(\"extra0 \") for prediction in predictions]\n",
    "    ground_truths = [ground_truth.strip() for ground_truth in ground_truths]\n",
    "    # shown one example\n",
    "    print(f\"predictions {predictions[0]}, ground_truths {ground_truths[0]}\")\n",
    "    score = sum(\n",
    "        [\n",
    "            prediction[: len(ground_truth)] == ground_truth\n",
    "            for prediction, ground_truth in zip(predictions, ground_truths)\n",
    "        ]\n",
    "    ) / len(ground_truths)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_constant_schedule_with_warmup,\n",
    ")  # use AdamW is a standard practice for transformer\n",
    "from transformers.optimization import Adafactor  # use Adafactor is the default setting for T5\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "tot_step = args.max_steps\n",
    "\n",
    "\n",
    "# normally we freeze the model when using soft_template. However, we keep the option to tune plm\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]  # it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "optimizer_grouped_parameters1 = [\n",
    "    {\n",
    "        \"params\": [p for n, p in prompt_model.plm.named_parameters() if (not any(nd in n for nd in no_decay))],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in prompt_model.plm.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer1 = AdamW(optimizer_grouped_parameters1, lr=args.lr)\n",
    "scheduler1 = get_linear_schedule_with_warmup(optimizer1, num_warmup_steps=500, num_training_steps=tot_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptForGeneration(\n",
       "  (prompt_model): PromptModel(\n",
       "    (plm): T5ForConditionalGeneration(\n",
       "      (shared): Embedding(21228, 768)\n",
       "      (encoder): T5Stack(\n",
       "        (embed_tokens): Embedding(21228, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (decoder): T5Stack(\n",
       "        (embed_tokens): Embedding(21228, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=21228, bias=False)\n",
       "    )\n",
       "    (template): ManualTemplate()\n",
       "  )\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss = 0\n",
    "log_loss = 0\n",
    "best_val_acc = 0\n",
    "glb_step = 0\n",
    "actual_step = 0\n",
    "leave_training = False\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "acc_traces = []\n",
    "tot_train_time = 0\n",
    "pbar_update_freq = 50\n",
    "prompt_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  71%|███████   | 3550/5000 [11:32<04:42,  5.13it/s, loss=1.85, epoch=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 500, val_acc 0.25919117647058826, average time 0.13028615856170656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 1000, val_acc 0.24632352941176472, average time 0.13074163126945496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 1500, val_acc 0.3775735294117647, average time 0.1308801472981771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 2000, val_acc 0.6209558823529412, average time 0.13095311641693116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 2500, val_acc 0.6080882352941176, average time 0.1313422209739685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 3000, val_acc 0.7470588235294118, average time 0.1313468804359436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 3500, val_acc 0.7794117647058824, average time 0.13135348987579346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 四, ground_truths 四\n",
      "Glb_step 4000, val_acc 0.7919117647058823, average time 0.1313677254319191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 四, ground_truths 四\n",
      "Glb_step 4500, val_acc 0.8180147058823529, average time 0.1314443656073676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n",
      "Glb_step 5000, val_acc 0.7610294117647058, average time 0.13144027066230773\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=tot_step, desc=\"Train\")\n",
    "for epoch in range(1000000):\n",
    "    for step, inputs in enumerate(train_dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        tot_train_time -= time.time()\n",
    "        loss = prompt_model(inputs)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        actual_step += 1\n",
    "\n",
    "        if actual_step % gradient_accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(prompt_model.parameters(), 1.0)\n",
    "            glb_step += 1\n",
    "            if glb_step % pbar_update_freq == 0:\n",
    "                aveloss = (tot_loss - log_loss) / pbar_update_freq\n",
    "                pbar.update(pbar_update_freq)\n",
    "                pbar.set_postfix({\"loss\": aveloss, \"epoch\": epoch})\n",
    "                log_loss = tot_loss\n",
    "\n",
    "                if optimizer1 is not None:\n",
    "                    optimizer1.step()\n",
    "                    optimizer1.zero_grad()\n",
    "                if scheduler1 is not None:\n",
    "                    scheduler1.step()\n",
    "\n",
    "        tot_train_time += time.time()\n",
    "\n",
    "        if actual_step % gradient_accumulation_steps == 0 and glb_step > 0 and glb_step % args.eval_every_steps == 0:\n",
    "            val_acc = evaluate(prompt_model, validation_dataloader)\n",
    "            if val_acc >= best_val_acc:\n",
    "                # torch.save(prompt_model.state_dict(),f\"{args.project_root}/../ckpts/{this_run_unicode}.ckpt\")\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "            acc_traces.append(val_acc)\n",
    "            print(\n",
    "                \"Glb_step {}, val_acc {}, average time {}\".format(glb_step, val_acc, tot_train_time / actual_step),\n",
    "                flush=True,\n",
    "            )\n",
    "            prompt_model.train()\n",
    "\n",
    "        if glb_step > args.max_steps:\n",
    "            leave_training = True\n",
    "            break\n",
    "\n",
    "    if leave_training:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input_ids\": [[101, 671, 8038, 3934, 4128, 4127, 1908, 3209, 8039, 753, 8038, 3655, 4128, 4127, 1348, 4197, 8039, 676, 8038, 3655, 4128, 3266, 1908, 3209, 8039, 1724, 8038, 3655, 4128, 4127, 1348, 3209, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 3210, 3266, 4638, 4128, 4219, 4127, 749, 1348, 6158, 7028, 3173, 4157, 778, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 674, 7027, 7474, 3702, 1812, 8039, 753, 8038, 674, 7027, 5318, 3702, 1812, 8039, 676, 8038, 674, 7027, 5318, 7599, 4170, 8039, 1724, 8038, 674, 7027, 5318, 1973, 3702, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 3882, 5782, 674, 7027, 8024, 2014, 1399, 6823, 2813, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 6501, 3341, 6124, 1071, 2227, 8039, 753, 8038, 6443, 5670, 5143, 1071, 678, 8039, 676, 8038, 1105, 3617, 5143, 1071, 2227, 8039, 1724, 8038, 2769, 3617, 2945, 1071, 2330, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 862, 1105, 2682, 5143, 857, 2124, 4638, 2227, 4999, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 2156, 3341, 3300, 7412, 7896, 8039, 753, 8038, 1298, 3341, 3300, 7896, 7412, 8039, 676, 8038, 4904, 3341, 2687, 7412, 7607, 8039, 1724, 8038, 4904, 3341, 1546, 3300, 7412, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 4904, 2108, 2347, 1168, 1372, 6224, 6121, 6121, 7607, 7412, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 1316, 4263, 4767, 3787, 3926, 8039, 753, 8038, 2170, 3787, 5632, 3926, 3815, 8039, 676, 8038, 4263, 3634, 2170, 3787, 3926, 8039, 1724, 8038, 4263, 3634, 3926, 4904, 1045, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 3926, 1110, 4638, 3787, 3717, 5283, 1112, 6851, 3209, 8024, 2685, 782, 1599, 4263, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 3144, 1898, 1962, 7881, 679, 4761, 1905, 8024, 1283, 675, 5972, 5850, 1367, 3312, 3210, 511, 8039, 753, 8038, 671, 1898, 4635, 7881, 679, 4761, 1905, 8024, 674, 4157, 7471, 2255, 6963, 1762, 1184, 511, 8039, 676, 8038, 3144, 1898, 1962, 7881, 679, 4761, 1905, 8024, 1283, 675, 5972, 5384, 1367, 3312, 3210, 511, 8039, 1724, 8038, 3144, 1898, 1582, 7881, 3187, 2192, 1905, 8024, 1126, 2428, 3162, 7345, 679, 1057, 3517, 511, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 6821, 3198, 794, 5001, 3360, 704, 837, 1139, 7347, 7347, 7881, 1373, 8024, 1377, 3221, 972, 1920, 4638, 5001, 3360, 704, 1316, 1355, 4385, 679, 749, 7881, 1036, 4638, 855, 5390, 8024, 1372, 8043, 5018, 21128, 1368, 511, 102], [101, 671, 8038, 5721, 2255, 5735, 3187, 6662, 8039, 753, 8038, 1184, 6121, 5735, 3187, 2255, 8039, 676, 8038, 1184, 2255, 679, 1377, 3353, 8039, 1724, 8038, 1184, 6121, 3187, 2495, 3189, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 1403, 1184, 7607, 6121, 849, 725, 2347, 3187, 2255, 2287, 7349, 4809, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 6468, 1278, 2208, 7178, 7270, 1316, 5790, 8024, 3265, 7755, 5168, 100, 5464, 955, 782, 511, 8039, 753, 8038, 7161, 674, 6589, 7178, 3119, 2896, 2533, 8024, 1168, 1928, 5303, 679, 3131, 7645, 2170, 511, 8039, 676, 8038, 2170, 5922, 1297, 1316, 6820, 3782, 1391, 8024, 1377, 3300, 7032, 6503, 2940, 2533, 3341, 511, 8039, 1724, 8038, 1297, 6132, 2533, 7178, 6963, 5287, 1316, 8024, 4567, 7755, 6006, 2170, 5464, 1048, 5359, 511, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 1184, 2399, 2828, 1297, 6132, 3302, 4638, 7178, 1059, 6956, 677, 769, 8024, 1914, 4567, 4638, 6716, 2094, 6006, 4197, 2170, 1107, 8024, 1377, 1048, 1343, 749, 6158, 5308, 5359, 1358, 3619, 8043, 5018, 21128, 1368, 511, 102, 0], [101, 671, 8038, 4759, 1226, 7599, 2972, 4565, 8039, 753, 8038, 1226, 7599, 3341, 1963, 1944, 8039, 676, 8038, 1226, 7599, 691, 1266, 3341, 8039, 1724, 8038, 1266, 7599, 1226, 1963, 1147, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 6006, 4197, 4385, 1762, 4638, 4312, 7599, 3341, 4638, 7478, 2382, 4338, 4164, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 833, 4942, 5162, 5669, 6947, 8039, 753, 8038, 1599, 833, 1911, 6947, 3952, 8039, 676, 8038, 5323, 2791, 2877, 833, 6947, 8039, 1724, 8038, 7471, 6151, 833, 4942, 100, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 833, 4942, 6821, 1036, 3300, 702, 1153, 3312, 5670, 4638, 2658, 6947, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 1166, 6662, 1426, 2199, 3504, 8039, 753, 8038, 2145, 6662, 3175, 5307, 3504, 8039, 676, 8038, 1166, 6662, 6841, 2101, 3504, 8039, 1724, 8038, 1139, 6125, 1166, 2101, 3504, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 696, 2135, 5466, 1372, 1728, 872, 2798, 6814, 2101, 3504, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 3634, 704, 2575, 6224, 2288, 4691, 2145, 8039, 753, 8038, 2575, 2554, 2288, 4691, 7434, 6760, 7770, 8039, 676, 8038, 2212, 704, 2575, 6224, 3960, 1298, 3250, 8039, 1724, 8038, 3634, 704, 3295, 6224, 2145, 3341, 1415, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 2769, 2575, 4197, 6878, 1168, 749, 2644, 6821, 855, 794, 2157, 740, 2288, 4691, 3341, 4638, 2145, 782, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 2769, 3341, 6225, 3717, 1908, 6225, 2255, 8039, 753, 8038, 6225, 3717, 6225, 2255, 4639, 2533, 1975, 8039, 676, 8038, 6225, 741, 2347, 5735, 6225, 2255, 3717, 8039, 1724, 8038, 6225, 3717, 6225, 2255, 1131, 6371, 1357, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 6225, 2255, 6225, 3717, 6963, 5543, 7566, 4526, 1975, 6637, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 711, 7309, 6205, 7599, 3341, 1126, 3189, 8024, 1911, 7345, 2151, 3671, 771, 4904, 1898, 511, 8039, 753, 8038, 2214, 7319, 4912, 1765, 6205, 7599, 7433, 8024, 711, 7309, 6205, 7599, 3193, 3241, 1726, 511, 8039, 676, 8038, 7731, 886, 1726, 3198, 3295, 2164, 6427, 8024, 6205, 7599, 3193, 3241, 3941, 4912, 2335, 511, 8039, 1724, 8038, 2400, 2336, 3191, 3189, 7599, 1898, 2626, 8024, 2580, 3307, 740, 741, 3193, 3241, 1726, 511, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 3295, 5307, 1420, 6432, 4912, 1765, 1167, 6629, 6205, 7599, 2218, 833, 678, 7433, 8024, 6205, 7599, 1557, 8024, 872, 784, 720, 3198, 952, 1726, 1343, 1557, 8043, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0], [101, 671, 8038, 2431, 1184, 5632, 3300, 2255, 8039, 753, 8038, 7305, 1912, 1927, 1184, 2255, 8039, 676, 8038, 5632, 6399, 7305, 1184, 2255, 8039, 1724, 8038, 7270, 2900, 7305, 1184, 2255, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 3395, 7305, 722, 1912, 6823, 2255, 5336, 5336, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 8038, 4170, 1045, 5770, 5682, 936, 3702, 3716, 8039, 753, 8038, 3959, 1045, 4170, 7461, 697, 3707, 3716, 8039, 676, 8038, 4170, 1045, 3381, 3918, 5770, 5682, 5297, 8039, 1724, 8038, 5770, 5682, 4170, 1045, 3265, 3617, 5892, 511, 1525, 671, 1368, 6134, 6809, 749, 678, 7481, 4638, 2692, 2590, 131, 4170, 1045, 7027, 5770, 5682, 3173, 7831, 8043, 5018, 21128, 1368, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"inputs_embeds\": null, \"attention_mask\": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"token_type_ids\": null, \"label\": [3, 3, 2, 3, 2, 2, 1, 3, 1, 0, 2, 0, 1, 1, 2, 0], \"decoder_input_ids\": [[21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0], [21128, 0, 0, 0, 0]], \"decoder_inputs_embeds\": null, \"soft_token_ids\": null, \"past_key_values\": null, \"loss_ids\": [[1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]], \"guid\": null, \"tgt_text\": [\"\\u56db\", \"\\u56db\", \"\\u4e09\", \"\\u56db\", \"\\u4e09\", \"\\u4e09\", \"\\u4e8c\", \"\\u56db\", \"\\u4e8c\", \"\\u4e00\", \"\\u4e09\", \"\\u4e00\", \"\\u4e8c\", \"\\u4e8c\", \"\\u4e09\", \"\\u4e00\"], \"encoded_tgt_text\": null, \"input_ids_len\": null}\n",
      "\n",
      "['input_ids', 'attention_mask', 'label', 'decoder_input_ids', 'loss_ids', 'tgt_text']\n"
     ]
    }
   ],
   "source": [
    "example = next(iter(validation_dataloader))\n",
    "print(example)\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['四', '四', '三', '四', '三', '三', '二', '四', '二', '一', '三', '一', '二', '二', '三', '一']\n",
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "print(example[\"tgt_text\"])\n",
    "print(example[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['三 三', '一 一', '三 三', '四 四', '一 一', '一 一', '二 二', '三 一', '二 二', '三 三', '三 二', '二 二', '四 四', '四 四', '四 二', '一 三']\n",
      "['四', '四', '三', '四', '三', '三', '二', '四', '二', '一', '三', '一', '二', '二', '三', '一']\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "prompt_model.eval()\n",
    "with torch.no_grad():\n",
    "    if use_cuda:\n",
    "        example = example.cuda()\n",
    "    _, output_sentence = prompt_model.generate(inputs, **generation_arguments, verbose=False)\n",
    "print(output_sentence)\n",
    "print(example[\"tgt_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 三, ground_truths 四\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8330882352941177"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(prompt_model, validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"G:\\dataset\\text_classify\\诗歌分类\"\n",
    "def load_local_dataset(path=\"../CCPM/\", split=\"train\"):\n",
    "    import json\n",
    "\n",
    "    with open(f\"{path}/{split}.jsonl\", \"r\", encoding=\"utf-8\") as fin:\n",
    "        L = fin.readlines()\n",
    "    data = []\n",
    "    for json_str in L:\n",
    "        result = json.loads(json_str)\n",
    "        # from IPython import embed; embed()\n",
    "        for idx, choice in enumerate(result[\"choices\"]):\n",
    "            result[f\"choice{idx}\"] = choice\n",
    "        result.pop(\"choices\")\n",
    "        if \"answer\" not in result:\n",
    "            label = None\n",
    "        else:\n",
    "            label = int(result[\"answer\"])\n",
    "\n",
    "        data.append(InputExample(meta=result, label=label))\n",
    "    return data\n",
    "\n",
    "\n",
    "dataset[\"test\"] = load_local_dataset(path=data_dir, split=\"test_public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"guid\": null,\n",
       "  \"label\": null,\n",
       "  \"meta\": {\n",
       "    \"choice0\": \"事主不尽年\",\n",
       "    \"choice1\": \"事君期尽年\",\n",
       "    \"choice2\": \"事主不及终\",\n",
       "    \"choice3\": \"万年不尽意\",\n",
       "    \"translation\": \"侍奉夫主，不能尽自己的天年。\"\n",
       "  },\n",
       "  \"text_a\": \"\",\n",
       "  \"text_b\": \"\",\n",
       "  \"tgt_text\": null\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: 不能直接用 PromptDataLoader, 这个要求有 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 2720it [00:02, 1170.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "\n",
    "mytemplate = ManualTemplate(\n",
    "    tokenizer=tokenizer,\n",
    "    text=\"\"\"一：{\"meta\":\"choice0\"}； 二： {\"meta\":\"choice1\"}； 三： {\"meta\":\"choice2\"}； 四：{\"meta\":\"choice3\"}。哪一句表达了下面的意思: {\"meta\":\"translation\", \"shortenable\":True, \"post_processing\": lambda x:x.strip('。')}？第{\"mask\"}句。 \"\"\",\n",
    ")\n",
    "myverbalizer = GenerationVerbalizer(tokenizer, label_words={0: \"一\", 1: \"二\", 2: \"三\", 3: \"四\"}, is_rule=False)\n",
    "\n",
    "test_dataloader = PromptDataLoader(\n",
    "    dataset=dataset[\"test\"],\n",
    "    template=mytemplate,\n",
    "    # 原来预测的时候不加这个就行了\n",
    "    # verbalizer=myverbalizer,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_wrapper=tokenizer_wrapper,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    teacher_forcing=False,\n",
    "    predict_eos_token=True,  # predict_eos_token=True or False are both ok\n",
    "    truncate_method=\"tail\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 一 ： 事 主 不 尽 年 ； 二 ： 事 君 期 尽 年 ； 三 ： 事 主 不 及 终 ； 四 ： 万 年 不 尽 意 。 哪 一 句 表 达 了 下 面 的 意 思 : 侍 奉 夫 主 ， 不 能 尽 自 己 的 天 年 ？ 第 extra0 句 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "extra0 [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# visualize some encoded data\n",
    "print(tokenizer.decode(next(iter(test_dataloader))[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(next(iter(test_dataloader))[\"decoder_input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 一\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for step, inputs in enumerate(test_dataloader):\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "    _, output_sentence = prompt_model.generate(inputs, **generation_arguments, verbose=False)\n",
    "    predictions.extend(output_sentence)\n",
    "predictions = [prediction.strip(\"extra0 \") for prediction in predictions]\n",
    "# shown one example\n",
    "print(f\"predictions {predictions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2720, 2720)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(test_dataloader.raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一', '一', '二', '二', '一', '四', '一', '二', '二', '二']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"guid\": null,\n",
       "  \"label\": null,\n",
       "  \"meta\": {\n",
       "    \"choice0\": \"事主不尽年\",\n",
       "    \"choice1\": \"事君期尽年\",\n",
       "    \"choice2\": \"事主不及终\",\n",
       "    \"choice3\": \"万年不尽意\",\n",
       "    \"translation\": \"侍奉夫主，不能尽自己的天年。\"\n",
       "  },\n",
       "  \"text_a\": \"\",\n",
       "  \"text_b\": \"\",\n",
       "  \"tgt_text\": null\n",
       "}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.raw_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "label_maps = {\n",
    "    \"一\": 0,\n",
    "    \"二\": 1,\n",
    "    \"三\": 2,\n",
    "    \"四\": 3,\n",
    "}\n",
    "\n",
    "with open(\"CCPM.jsonl\", \"w\", encoding=\"utf-8\") as fw, open(os.path.join(data_dir, \"test_public.jsonl\"), \"r\", encoding=\"utf-8\") as fr:\n",
    "    lines = fr.readlines()\n",
    "    for line, predict in zip(lines, predictions):\n",
    "        result = json.loads(line)\n",
    "        result[\"answer\"] = label_maps[predict]\n",
    "        fw.write(json.dumps(result, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评测成绩 81.65\n",
    "\n",
    "排行榜上的第一位是 93.82, 差距还是非常大."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
