{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "\n",
    "classes = [\"negative\", \"positive\"]  # There are two classes in Sentiment Analysis, one for negative and one for positive\n",
    "dataset = [  # For simplicity, there's only two examples\n",
    "    # text_a is the input text of the data, some other datasets may have multiple input sentences in one example.\n",
    "    InputExample(\n",
    "        guid=0,\n",
    "        text_a=\"Albert Einstein was one of the greatest intellects of his time.\",\n",
    "    ),\n",
    "    InputExample(\n",
    "        guid=1,\n",
    "        text_a=\"The film was badly made.\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 加载预训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ee8f169f2446cba3328136a171d954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea37a258688a4049b2ff7631b43e231c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76b45fd5cdc461e85f114328ab55b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e46df3ca4f41988c471b47a5c38ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openprompt.plms import load_plm\n",
    "\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 定义模板\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "\n",
    "promptTemplate = ManualTemplate(\n",
    "    text='{\"placeholder\":\"text_a\"} It was {\"mask\"}',\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'Albert Einstein was one of the greatest intellects of his time.',\n",
       "   'loss_ids': 0,\n",
       "   'shortenable_ids': 1},\n",
       "  {'text': ' It was', 'loss_ids': 0, 'shortenable_ids': 0},\n",
       "  {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}],\n",
       " {'guid': 0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTemplate.wrap_one_example(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 定义标签映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualVerbalizer\n",
    "\n",
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes=classes,\n",
    "    label_words={\n",
    "        \"negative\": [\"bad\"],\n",
    "        \"positive\": [\"good\", \"wonderful\", \"great\"],\n",
    "    },\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.定义提示模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt import PromptForClassification\n",
    "\n",
    "promptModel = PromptForClassification(\n",
    "    template=promptTemplate,\n",
    "    plm=plm,\n",
    "    verbalizer=promptVerbalizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.定义数据加载器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 2it [00:00, 1961.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader\n",
    "\n",
    "data_loader = PromptDataLoader(\n",
    "    dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    template=promptTemplate,\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input_ids\": [[101, 3986, 16127, 1108, 1141, 1104, 1103, 4459, 1107, 7854, 18465, 1116, 1104, 1117, 1159, 119, 1135, 1108, 103, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"inputs_embeds\": null, \"attention_mask\": [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"token_type_ids\": null, \"label\": null, \"decoder_input_ids\": null, \"decoder_inputs_embeds\": null, \"soft_token_ids\": null, \"past_key_values\": null, \"loss_ids\": [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"guid\": [0], \"tgt_text\": null, \"encoded_tgt_text\": null, \"input_ids_len\": null}\n",
      "\n",
      "input_ids torch.Size([1, 32]) tensor([[  101,  3986, 16127,  1108,  1141,  1104,  1103,  4459,  1107,  7854,\n",
      "         18465,  1116,  1104,  1117,  1159,   119,  1135,  1108,   103,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "attention_mask torch.Size([1, 32]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "loss_ids torch.Size([1, 32]) tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    1, -100,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "guid torch.Size([1]) tensor([0])\n",
      "['[CLS]', 'Albert', 'Einstein', 'was', 'one', 'of', 'the', 'greatest', 'in', '##tel', '##lect', '##s', 'of', 'his', 'time', '.', 'It', 'was', '[MASK]', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(next(iter(data_loader)))\n",
    "example = next(iter(data_loader))\n",
    "\n",
    "for key, val in example.items():\n",
    "    print(key, val.shape, val)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(example[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.训练和推理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# making zero-shot inference using pretrained MLM with prompt\n",
    "promptModel.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        logits = promptModel(batch)\n",
    "        preds = torch.argmax(logits, dim = -1)\n",
    "        print(classes[preds])\n",
    "# predictions would be 1, 0 for classes 'positive', 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模板\n",
    "\n",
    "TODO: 模板的文档里没有介绍 placeholder, 但上面的示例用了.\n",
    "\n",
    "模板是由多个 dict 组成的, key 可以是\n",
    "\n",
    "- meta: 原始文本输入字段, 也可以是其他 key information\n",
    "- mask: 是需要预测的文本\n",
    "- soft: soft token, TODO: 具体是啥, 可以修改的 prompt 吗?\n",
    "- text: 纯文本, 可以直接写不需要包装\n",
    "\n",
    "```\n",
    "# 情感分类\n",
    "{\"meta\": \"sentence\"}. It is {\"mask\"}.\n",
    "\n",
    "# 新闻分类\n",
    "A {\"mask\"} news : {\"meta\": \"title\"} {\"meta\": \"description\"}\n",
    "\n",
    "# 纯文本可以直接写\n",
    "{\"meta\": \"sentence\"} {\"text\": \"In this sentence,\"} {\"meta\": \"entity\"} {\"text\": \"is a\"} {\"mask\"},\n",
    "{\"meta\": \"sentence\"}. In this sentence, {\"meta\": \"entity\"} is a {\"mask\"},\n",
    "\n",
    "# soft 字段\n",
    "{\"meta\": \"premise\"} {\"meta\": \"hypothesis\"} {\"soft\": \"Does the first sentence entails the second?\"} {\"mask\"} {\"soft\"}.\n",
    "{\"soft\": None, \"duplicate\": 10000} {\"meta\": \"text\"} {\"mask\"}\n",
    "{\"soft\": None, \"duplicate\": 10000, \"same\": True}\n",
    "\n",
    "# 支持后处理\n",
    "{\"meta\": 'context', \"post_processing\": lambda s: s.rstrip(string.punctuation)}. {\"soft\": \"It was\"} {\"mask\"}\n",
    "{\"text\": \"This sentence is\", \"post_processing\": \"mlp\"} {\"soft\": None, \"post_processing\": \"mlp\"}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义标签映射\n",
    "\n",
    "需要定义标签映射\n",
    "\n",
    "```python\n",
    "ManualVerbalizer(\n",
    "    label_words=label_words,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "`label_words` 可以是多种格式, 如果数组, 嵌套数组, 字典.\n",
    "字典最直观, 一个标签可以对应多个标签映射.\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"person-scholar\": [\"scholar\", \"scientist\"],\n",
    "    \"building-library\": [\"library\"],\n",
    "    \"building-hotel\": [\"hotel\"],\n",
    "    \"location-road/railway/highway/transit\": [\"road\", \"railway\", \"highway\", \"transit\"]\n",
    "}\n",
    "```\n",
    "\n",
    "也可以从文件中加载.\n",
    "\n",
    "```python\n",
    "ManualVerbalizer(...).from_file(file_path=file_path)\n",
    "```\n",
    "\n",
    "文件有个优势是可以有多组标签映射, 需要的时候使用 choice 选择对应的标签映射组.\n",
    "\n",
    "```python\n",
    "ManualVerbalizer(...).from_file(file_path=file_path, choice=0)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
